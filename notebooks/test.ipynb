{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Import selenium necessities\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Chrome WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "prefs = {\"profile.managed_default_content_settings.images\": 2}\n",
    "options.add_experimental_option(\"prefs\", prefs)\n",
    "# options.add_argument('--headless')\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "driver = webdriver.Chrome(options=options)\n",
    "# driver.implicitly_wait(60)\n",
    "\n",
    "URL = \"https://pagination.js.org\"\n",
    "driver.get(URL)\n",
    "# time.sleep(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_page = driver.find_element(By.XPATH, '//*[@id=\"demo1\"]/div[2]/div/ul/li[9]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "all_list_elements = driver.find_elements(By.XPATH, '//*[@id=\"demo1\"]/div[2]/div/ul/li')\n",
    "\n",
    "# In this case (by manual checking), element [-1] contains the last page number\n",
    "number_of_pages = int(all_list_elements[-2].text)\n",
    "print(number_of_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract data from current page\n",
    "def extract_page_data(driver):\n",
    "    page_output = []\n",
    "\n",
    "    # Locate all elements on the current page\n",
    "    page_elements = driver.find_elements(By.XPATH, '//*[@id=\"demo1\"]/div[1]/ul/li')\n",
    "\n",
    "    # Iterate through each element in the page\n",
    "    for each_element in page_elements:\n",
    "        # Extract the text content of each element\n",
    "        each_element_value = each_element.get_attribute('innerHTML')\n",
    "        page_output.append(each_element_value)\n",
    "\n",
    "    print(page_output)\n",
    "\n",
    "    return page_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
      "['11', '12', '13', '14', '15', '16', '17', '18', '19', '20']\n",
      "['21', '22', '23', '24', '25', '26', '27', '28', '29', '30']\n",
      "['31', '32', '33', '34', '35', '36', '37', '38', '39', '40']\n",
      "['41', '42', '43', '44', '45', '46', '47', '48', '49', '50']\n",
      "['51', '52', '53', '54', '55', '56', '57', '58', '59', '60']\n",
      "['61', '62', '63', '64', '65', '66', '67', '68', '69', '70']\n",
      "['71', '72', '73', '74', '75', '76', '77', '78', '79', '80']\n",
      "['81', '82', '83', '84', '85', '86', '87', '88', '89', '90']\n",
      "['91', '92', '93', '94', '95', '96', '97', '98', '99', '100']\n",
      "['101', '102', '103', '104', '105', '106', '107', '108', '109', '110']\n",
      "['111', '112', '113', '114', '115', '116', '117', '118', '119', '120']\n",
      "['121', '122', '123', '124', '125', '126', '127', '128', '129', '130']\n",
      "['131', '132', '133', '134', '135', '136', '137', '138', '139', '140']\n",
      "['141', '142', '143', '144', '145', '146', '147', '148', '149', '150']\n",
      "['151', '152', '153', '154', '155', '156', '157', '158', '159', '160']\n",
      "['161', '162', '163', '164', '165', '166', '167', '168', '169', '170']\n",
      "['171', '172', '173', '174', '175', '176', '177', '178', '179', '180']\n",
      "['181', '182', '183', '184', '185', '186', '187', '188', '189', '190']\n",
      "['191', '192', '193', '194', '195']\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the pages\n",
    "final_out = []\n",
    "for page_num in range(number_of_pages):\n",
    "    # Extract the data from the current page\n",
    "    page_output = extract_page_data(driver)\n",
    "    # Add the data to the final_out list as a dictionary with the page number as the key\n",
    "    final_out.append({\n",
    "        page_num: page_output\n",
    "    })\n",
    "    # Locate the \"Next\" button on the webpage and click it to navigate to the next page\n",
    "    next_page = driver.find_element(By.XPATH, \"//a[text()='â€º']\").click()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
